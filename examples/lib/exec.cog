flow exec(response: Map, tools: List = [], max_turns: Int = 10, system: String = "", model: String = "deepseek-chat") -> Map:
    "Agentic tool loop: run tool calls, feed results back to LLM, repeat.
     The system prompt is preserved across all turns for context continuity."
    
    current = response
    turn = 0
    # Keep a rolling history of the last 3 turns to maintain context
    history = []
    
    loop:
        if turn >= max_turns:
            break
        if current["has_tool_calls"] == false:
            break
        
        # Execute all tool calls
        tool_results = []
        for call in current["tool_calls"]:
            name = call["name"]
            args = call["arguments"]
            result = invoke(name, args)
            result_str = f"{result}"
            if result_str.length > 3000:
                result_str = result_str[:3000] + "\n... (truncated)"
            tool_results = tool_results + [f"[{name}({args}) returned]:\n{result_str}"]
        
        tool_output = tool_results.join("\n\n")
        
        # Add to rolling history (keep last 3 turns)
        history = history + [f"Turn {turn + 1} tool results:\n{tool_output}"]
        if history.length > 3:
            history = history[history.length - 3:]
        
        # Build context with history
        context = history.join("\n---\n")
        
        # Call LLM with system prompt preserved + tool results
        current = think(
            f"Previous tool results:\n{context}\n\nContinue working on the task. Use tools if needed, or provide your final answer when done.",
            model=model,
            tools=tools,
            system=system
        )
        turn = turn + 1
    
    return {"content": current["content"], "has_tool_calls": false, "turns": turn}
