flow exec(response: Map, tools: List = [], max_turns: Int = 15, system: String = "", model: String = "deepseek-chat") -> Map:
    "Agentic tool loop: run tool calls, feed results back to LLM, repeat.
     System prompt preserved. Full history maintained but summarized."
    
    current = response
    turn = 0
    history = []
    
    loop:
        if turn >= max_turns:
            break
        if current["has_tool_calls"] == false:
            break
        
        # Execute all tool calls
        tool_results = []
        for call in current["tool_calls"]:
            name = call["name"]
            args = call["arguments"]
            result = invoke(name, args)
            result_str = f"{result}"
            if result_str.length > 2000:
                result_str = result_str[:2000] + "\n...(truncated)"
            tool_results = tool_results + [f"[{name} returned]: {result_str}"]
        
        tool_output = tool_results.join("\n")
        
        # Keep rolling window of 4 turns
        history = history + [f"Turn {turn + 1}:\n{tool_output}"]
        if history.length > 4:
            history = history[history.length - 4:]
        
        context = history.join("\n---\n")
        
        # Urgency escalation after turn 8
        urgency = ""
        if turn >= 8:
            urgency = "\n\nURGENT: You have used most of your turns. STOP searching and make your edit NOW using edit_file(). If you have identified the bug, fix it immediately."
        
        current = think(
            f"Previous results:\n{context}{urgency}\n\nContinue working. Use tools if needed, or provide your final answer.",
            model=model,
            tools=tools,
            system=system
        )
        turn = turn + 1
    
    return {"content": current["content"], "has_tool_calls": false, "turns": turn}
