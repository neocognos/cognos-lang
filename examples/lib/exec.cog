flow exec(response: Map, tools: List = [], max_turns: Int = 20, system: String = "", model: String = "claude-sonnet-4-20250514") -> Map:
    "Multi-turn agentic tool loop with conversation history.
     Uses native Anthropic conversation API. Progressive truncation prevents context overflow."
    
    current = response
    turn = 0
    # Support both multi-turn (has conversation) and single-turn/mock mode
    conversation = none
    try:
        conversation = current["conversation"]
    catch e:
        conversation = none
    
    loop:
        if turn >= max_turns:
            break
        if current["has_tool_calls"] == false:
            break
        
        # Progressive truncation: shorter limits as conversation grows
        max_result = 4000
        if turn > 5:
            max_result = 2000
        if turn > 10:
            max_result = 1000
        
        # Execute all tool calls and build tool_results
        results = []
        for call in current["tool_calls"]:
            name = call["name"]
            args = call["arguments"]
            call_id = ""
            try:
                call_id = call["id"]
            catch e:
                call_id = f"call_{turn}_{name}"
            result = invoke(name, args)
            result_str = f"{result}"
            # Truncate with head+tail preservation
            if result_str.length > max_result:
                head_size = max_result * 6 / 10
                tail_size = max_result * 3 / 10
                result_str = result_str[:head_size] + f"\n\n... ({result_str.length} chars, truncated at turn {turn}) ...\n\n" + result_str[result_str.length - tail_size:]
            results = results + [{"tool_use_id": call_id, "content": result_str}]
        
        # Send tool results back â€” use conversation mode if available, else single-turn
        if conversation != none:
            current = think(
                "",
                model=model,
                tools=tools,
                system=system,
                conversation=conversation,
                tool_results=results
            )
        else:
            # Single-turn fallback: build context from tool results
            tool_context = ""
            for r in results:
                tid = r["tool_use_id"]
                tcontent = r["content"]
                tool_context = tool_context + f"Tool {tid}: {tcontent}\n"
            current = think(
                f"Tool results:\n{tool_context}\n\nContinue with the task. Use more tools if needed, or provide your final answer.",
                model=model,
                tools=tools,
                system=system
            )
        
        try:
            conversation = current["conversation"]
        catch e:
            log("No conversation in response, continuing without history")
        turn = turn + 1
    
    # Add final turn warning if we hit max
    status = "done"
    if turn >= max_turns:
        status = "max_turns"
    
    return {"content": current["content"], "has_tool_calls": false, "turns": turn, "status": status}
